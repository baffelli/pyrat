import os
import glob
import re
import pyrat.fileutils.gpri_files as gpf
import pyrat.core.corefun as cf
import pyrat.gpri_utils.calibration as cal
import pyrat.core.matrices as mat
from snakemake.remote.SFTP import RemoteProvider

#this matches a slc name in the form YYYYMMDD_HHMMSS or YYYYMMDD_HHMMSS_TXRXRX{upper or lower}
slc_regex = "(\d{8})_(\d{6})((_[A-B]{3}[l-u]))?"


#ruleorder: copy_raw > extract_channel
#ruleorder: range_compression > coregister_channels
ruleorder: extract_channel > range_compression

if 'coregistration' not in config:
    config['coregistration'] = {
            'rlks':1,
            'azlks':1,
            'rlks_init':1,
            'azlks_init':2,
            'rwin_init':64,
            'azwin_init':64,
            'rwin':64,
            'azwin':64,
            'noff_r':20,
            'noff_az':20,
            'ridx': '-',
            'azidx': '-',
                           }



if config['project_name']:
    ##############################################################################
    # This rule links the raw data to the local working directory for a nicer folder structure
    rule link_data_to_working_directory:
        input:
            raw = "/data/{project_name}/raw/{{date}}_{{time}}.raw".format(project_name=config['project_name']),
            raw_par = "/data/{project_name}/raw/{{date}}_{{time}}.raw_par".format(project_name=config['project_name']),
        output:
            raw = "raw/{date}_{time}.raw",
            raw_par = "raw/{date}_{time}.raw_par",
        run:
            shell("ln -s {input.raw} {output.raw}")
            shell("ln -s {input.raw}_par {output.raw_par}")



##############################################################################
## This rule processes data with the conventional gpri processor
rule standard_processor:
	input:
		raw = "raw/{dataname}.raw",
		raw_par = "raw/{dataname}.raw_par",
	output:
		slc_l =  "slc_standard/{dataname}_{chan}l.slc",
		slc_u =  "slc_standard/{dataname}_{chan}u.slc"
	params:
		chan = lambda wildcards: "{chan}".format(chan=wildcards.chan)[0:3],
		slc_id = lambda wildcards: "slc_standard/{dataname}".format(chan=wildcards.chan, dataname=wildcards.dataname),
	shell:
		"""
		gpri2_proc_multi.py {input.raw}  {input.raw_par} {params.slc_id} -p {params.chan} -r {config[range_compression][rmin]} -R {config[range_compression][rmax]} -k {config[range_compression][k]} -z {config[range_compression][z]}
		"""


#This part is the one used to obtain corrected & coregistered slcs
##############################################################################
### Extract channel from raw data
rule extract_channel:
    input:
        raw = "raw/{dataname}.raw",
        raw_par = "raw/{dataname}.raw_par",
    output:
        chan = "raw_chan/{dataname}_{chan}.raw",
        chan_par = "raw_chan/{dataname}_{chan}.raw_par"
    run:
        raw = gpf.rawData(input.raw_par, input.raw, channel_mapping=config['channel_mapping'])
        raw_chan = raw.extract_channel(wildcards.chan[0:3], wildcards.chan[-1])
        raw_chan.tofile(output.chan_par, output.chan)




##############################################################################
## Correct squint
rule correct_squint:
		input:
			raw = "raw_chan/{dataname}_{chan,[A-B]{3}}{rx}.raw",
			raw_par = "raw_chan/{dataname}_{chan,[A-B]{3}}{rx}.raw_par",
		output:
			corr =  "raw_desq/{dataname}_{chan,[A-B]{3}}{rx}.raw",
			corr_par = "raw_desq/{dataname}_{chan,[A-B]{3}}{rx}.raw_par"
		params:
			squint_rate = lambda wildcards: config["desquint"]["{chan}_squint_rate".format(chan=wildcards.chan)],
		run:
			raw = gpf.rawData(input.raw_par, input.raw)
			raw_desq = gpf.correct_squint(raw, squint_rate=params.squint_rate)
			raw_desq.tofile(output.corr_par, output.corr)






##############################################################################
## Range compression
rule range_compression:
    input:
        raw = "raw_{type}/{rawname}.raw",
        raw_par = "raw_{type}/{rawname}.raw_par",
    output:
        slc = "slc_{type, (desq)|(chan)}/{rawname}.slc",
        slc_par = "slc_{type, (desq)|(chan)}/{rawname}.slc.par"
    run:
        raw = gpf.rawData(input.raw_par, input.raw)
        slc = gpf.range_compression(raw, rmin=config['range_compression']['rmin'], rmax=config['range_compression']['rmax'],
        kbeta=config['range_compression']['k'], dec=1, zero=config['range_compression']['z'], f_c=None, bw=66e6, rvp_corr=False, scale=True)
        slc.tofile(output.slc_par, output.slc)




###############################################################################
### Find the shift between two SLCs
rule slc_shift:
    input:
        slave_slc = 'slc_desq/{slcname1}.slc',
        master_slc = 'slc_desq/{slcname2}.slc',
        slave_slc_par = 'slc_desq/{slcname2}.slc.par',
        master_slc_par = 'slc_desq/{slcname1}.slc.par',
    output:
        offs = "diff/{slcname1}_{slcname2}.offs",
        snr =  "diff/{slcname1}_{slcname2}.ccp",
        shift_par = "diff/{slcname1}_{slcname2}.off_par"
    wildcard_constraints:
        slcname1=slc_regex,
        slcname2=slc_regex
    run:
        #Create offset parameters
        diff_cmd = "create_offset {input.master_slc_par} {input.slave_slc_par} {output.shift_par} 1 {config[coregistration][rlks]} {config[coregistration][azlks]} 0"
        shell(diff_cmd)
        #Initial offset estimate
        init_offset_cmd = "init_offset {input.master_slc}  {input.slave_slc} {input.master_slc_par} {input.slave_slc_par} {output.shift_par} {config[coregistration][rlks]} {config[coregistration][azlks]} {config[coregistration][ridx]} {config[coregistration][azidx]} 0 0 0.1 {config[coregistration][rwin]} {config[coregistration][azwin]} 1"
        shell(init_offset_cmd)
        #Compute offset field
        offset_cmd =  "offset_pwr {input.master_slc} {input.slave_slc} {input.master_slc_par} {input.slave_slc_par} {output.shift_par} {output.offs} {output.snr} {config[coregistration][rwin]} {config[coregistration][azwin]} - - {config[coregistration][noff_r]} {config[coregistration][noff_az]} 0.3 "
        shell(offset_cmd)
        #        #Fit offset polynomial
        fit_cmd = "offset_fit {output.offs} {output.snr} {output.shift_par} - - 0.3 1 0"
        shell(fit_cmd)
        input



###############################################################################
### Using the found shift data, correct the shift (supposing HV shift is 1/2 of HH-VV shift)
rule correct_polarimetric_shift:
    input:
        slc = 'slc_desq/{slcname}_{chan}{rx}.slc',
        slc_par = 'slc_desq/{slcname}_{chan}{rx}.slc.par',
        off_par = 'diff/{slcname}_BBB{rx}_{slcname}_AAA{rx}.off_par',
    output:
        #add a postfix to the coregistered files for the case where an additional coregistration step to a common master is necessary
        coreg_slc = 'slc_coreg{temp,.*}/{slcname}_{chan}{rx,(l|u)}.slc',
        coreg_slc_par = 'slc_coreg{temp,.*}/{slcname}_{chan}{rx, (l|u)}.slc.par',
    params:
        coreg_off_par = 'diff/{slcname}_{chan}{rx}_{slcname}_AAA{rx}.off_par'#temporary offset parameter for resampling
    run:
        #Compute the amount of shift (0 for AAA, the full for BBB and 1/2 for the remaining)
        off_multiplier = {'AAA':0.0, 'BBB':1.0, 'BAA':0.5, 'ABB':0.5}
        az_mutliplier = off_multiplier[wildcards.chan]
        coreg_off_par = gpf.par_to_dict(input.off_par)
        #Modify the azimuth shift using the multplier
        coreg_off_par.azimuth_offset_polynomial[-1] *= az_mutliplier
        coreg_off_par.range_offset_polynomial = [0 for el in coreg_off_par.range_offset_polynomial]#We do not need to correct range shift
        gpf.dict_to_par(coreg_off_par, params.coreg_off_par)
        interp_cmd = "SLC_interp {input.slc} {input.slc_par} {input.slc_par} {params.coreg_off_par} {output.coreg_slc} -"
        cp_cmd = shell("cp {input.slc_par} {output.coreg_slc_par}")
        shell(interp_cmd)
        shell(cp_cmd)






if 'master_slc' in config:
    ruleorder: coregister_to_master > correct_polarimetric_shift
    rule coregister_to_master:
        input:
            slave_slc = 'slc_coreg_temp/{slcname}_{chan}.slc',
            master_slc = 'slc_coreg_temp/' + config['master_slc'] + '.slc',
            slave_slc_par = 'slc_coreg_temp/{slcname}_{chan}.slc.par',
            master_slc_par = 'slc_coreg_temp/' + config['master_slc'] + '.slc.par',
            shift_par = "diff/{{slcname}}_AAAl_{master}.off_par".format(master=config['master_slc']),
        output:
            coreg_slave_slc = 'slc_coreg/{slcname}_{chan}.slc',
            coreg_slave_slc_par = 'slc_coreg/{slcname}_{chan}.slc.par',
        wildcard_constraints:
            slcname1=slc_regex,
            slcname2=slc_regex
        run:
            interp_cmd = "SLC_interp {input.slave_slc} {input.master_slc_par} {input.slave_slc_par} {input.shift_par} {output.coreg_slave_slc} -"
            cp_cmd = shell("cp {input.slave_slc_par} {output.coreg_slave_slc_par}")
            shell(cp_cmd)
            shell(interp_cmd)






##############################################################################
## Correct the azimuth ramp in the image
rule correct_azimuth_ramp:
    input:
        slc = 'slc_coreg/{dataname}_{chan}.slc',
        slc_par = 'slc_coreg/{dataname}_{chan}.slc.par',
    output:
        slc = 'slc_corr/{dataname}_{chan}.slc',
        slc_par = 'slc_corr/{dataname}_{chan}.slc.par'
    wildcard_constraints:
        chan = "[A-B]{3}[l,u]{1}"
    params:
        integration_length = config['phase_correction']['integration_length'],
        r_ph = lambda wildcards: config['phase_correction']['{chan}_phase_center_offset'.format(chan=wildcards.chan[:-1:])],
    run:
        slc_input = gpf.gammaDataset(input.slc_par, input.slc)
        slc_corr = cal.azimuth_correction(slc_input, params.r_ph, ws=params.integration_length)
        slc_corr.tofile(output.slc_par, output.slc)

##############################################################################
## Make a mli image
rule multi_look:
    input:
        slc = '{file}.slc{ext}'
    wildcard_constraints:
        ext = "(.*|_dec)"
    output:
        mli = '{file}.mli{ext}',
        mli_par = '{file}.mli{ext}.par'
    run:
        shell("multi_look {input.slc} {input.slc}.par {output.mli} {output.mli_par} 1 1")


##############################################################################
## Decimate the samples in azimuth
rule decimate:
    input:
        slc = "slc_{proc}/{filename}.slc",
        slc_par = "slc_{proc}/{filename}.slc.par",
    output:
        slc = "slc_{proc}/{filename}.slc_dec",
        slc_par = "slc_{proc}/{filename}.slc_dec.par",
    params:
        dec = config["range_compression"]['dec'],
        dec_mode= lambda wildcards: 'other' if wildcards.proc == 'corr' else 'sum',
    run:
        from scipy.ndimage import zoom
        slc_input = gpf.gammaDataset(input.slc_par, input.slc)
        print(slc_input._params)
        slc_dec = slc_input.decimate(params.dec, mode=params.dec_mode)
        slc_dec.tofile(output.slc_par, output.slc)








